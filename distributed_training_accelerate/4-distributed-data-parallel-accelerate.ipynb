{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBuRkLzpKc48nA9BObSqYd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jKjo3Lv-CJJe"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Introduction to the `accelerate` Package\n","\n","The `accelerate` package, developed by Hugging Face, is designed to simplify and streamline the process of training and deploying PyTorch models across various hardware configurations, including multiple GPUs, TPUs, and distributed environments. :contentReference[oaicite:0]{index=0}\n","\n","## Key Features\n","\n","- **Unified API**: Provides a consistent interface for training and inference, abstracting away the complexities of different hardware setups.\n","- **Automatic Device Placement**: Automatically places models and data on the appropriate device, eliminating the need for manual device management.\n","- **Mixed Precision Training**: Supports mixed precision training to accelerate computations and reduce memory usage.\n","- **Distributed Training**: Facilitates distributed training across multiple GPUs or TPUs with minimal code changes.\n","\n","## Installation\n","\n","To install the `accelerate` package, use pip:\n","\n","```bash\n","pip install accelerate\n","```\n","\n","\n","## Basic Usage\n","Here's a simple example of how to use accelerate in a PyTorch training loop:\n","\n","```python\n","from accelerate import Accelerator\n","\n","# Initialize the accelerator\n","accelerator = Accelerator()\n","\n","# Prepare your model, optimizer, and dataloaders\n","model, optimizer, train_dataloader, scheduler = accelerator.prepare(\n","    model, optimizer, train_dataloader, scheduler\n",")\n","\n","for batch in train_dataloader:\n","    optimizer.zero_grad()\n","    inputs, targets = batch\n","    outputs = model(inputs)\n","    loss = loss_function(outputs, targets)\n","    accelerator.backward(loss)\n","    optimizer.step()\n","    scheduler.step()\n","```\n","\n","## Multi-GPU / Distributed Training\n","\n","### Running Multi-GPU Training:\n","  - `accelerate launch --multi_gpu --num_processes 4 script.py`\n","\n","### Enable Distributed Training in Code:\n","  - ```python\n","    accelerator = Accelerator()\n","    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n","    ```\n","  - `accelerator.prepare()` automatically adapts to DDP (DistributedDataParallel).\n","\n","---"],"metadata":{"id":"b6fcuxqECVbI"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from torch.optim import Adam\n","from torchtext.datasets import YelpReviewFull\n","from accelerate import Accelerator\n","import os\n","\n","# Initialize the Accelerator\n","accelerator = Accelerator()\n","\n","# Load tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\"\n",")\n","\n","# Custom Dataset class to handle YelpReviewFull dataset\n","class YelpDataset(Dataset):\n","    def __init__(self, split=\"train\"):\n","        super().__init__()\n","        self.data = list(YelpReviewFull(split=split))  # Load dataset into memory\n","\n","    def __getitem__(self, index):\n","        return self.data[index][1], self.data[index][0] - 1  # Adjust labels to be 0-based\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","# Create dataset instances\n","train_dataset = YelpDataset(split=\"train\")\n","valid_dataset = YelpDataset(split=\"test\")\n","\n","# Function to preprocess batches (tokenization, padding, and conversion to tensors)\n","def collate_fn(batch):\n","    texts, labels = zip(*batch)\n","    inputs = tokenizer(list(texts), max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","    inputs[\"labels\"] = torch.tensor(labels)\n","    return inputs\n","\n","# Create DataLoaders for training and validation. No need to use sampler\n","train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=collate_fn)\n","\n","# Optimizer setup\n","optimizer = Adam(model.parameters(), lr=2e-5)\n","\n","# # Function to ensure only rank 0 prints log messages\n","# # Can be replace by accelerator.print\n","# def print_rank_0(info):\n","#     if accelerator.is_local_main_process:\n","#         print(info)\n","\n","# Evaluation function\n","def evaluate():\n","    model.eval()\n","    acc_num = 0\n","    with torch.inference_mode():\n","        for batch in valid_loader:\n","            output = model(**batch)\n","            pred = torch.argmax(output.logits, dim=-1)\n","            # Gather predictions and references\n","            pred, refs = accelerator.gather_for_metrics((pred, batch[\"labels\"]))\n","\n","            # Ensure predictions and references are on the same device for comparison\n","            acc_num += (pred.long() == refs.long()).float().sum()\n","\n","    return acc_num / len(valid_loader.dataset)\n","\n","\n","# Training function\n","def train(epochs=3, log_step=100):\n","    global_step = 0\n","    model, optimizer, train_loader, valid_loader = accelerator.prepare(\n","        model, optimizer, train_loader, valid_loader\n","    )\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        for batch in train_loader:\n","            # batch = {k: v.to(model.device) for k, v in batch.items()}  # No need as accelerator will do for us\n","\n","            optimizer.zero_grad()\n","            output = model(**batch)\n","            loss = output.loss\n","            accelerator.backward(loss)  # accelerator backward\n","            optimizer.step()\n","\n","            # Log training progress on rank 0\n","            if global_step % log_step == 0:\n","                loss = accelerator.reduce(loss, \"mean\")\n","                accelerator.print(f\"ep: {ep}, global_step: {global_step}, loss: {loss.item()}\")\n","            global_step += 1\n","\n","        # Evaluate the model after each epoch\n","        acc = evaluate()\n","        accelerator.print(f\"Epoch: {epoch}, Accuracy: {acc}\")\n","\n","# Start training\n","train()\n","\n","# Cleanup\n","accelerator.end_training()\n"],"metadata":{"id":"qSFt1YjTCVzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !torchrun --nproc_per_node=2 ddp_accelerator.py\n","# !accelerate launch ddp_accelerator.py\n"],"metadata":{"id":"ExO8hoSCET2K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The default configuration path for Accelerate is typically located in the userâ€™s home directory under the .cache/huggingface/accelerate folder. The file is usually called default_config.yaml.\n","\n","Default Configuration Path:\n","Path: ~/.cache/huggingface/accelerate/default_config.yaml\n","You can also use the accelerate config command to configure or view settings interactively, which will save the configuration to this default file.\n","This YAML file contains configuration settings for distributed training, including options like the number of processes, mixed precision, and device settings."],"metadata":{"id":"gJa98ZQBIdQ9"}},{"cell_type":"code","source":["# !accelerate config"],"metadata":{"id":"TpZ-Tmq2Hj3R"},"execution_count":null,"outputs":[]}]}